# ============================================================================
# MirrorBuddy - ENVIRONMENT CONFIGURATION
# https://github.com/FightTheStroke/MirrorBuddy
#
# Copy this file to .env and fill in your values
# Contact: roberdan@fightthestroke.org
# ============================================================================

# ============================================================================
# AI PROVIDERS (Choose one for chat, Azure required for voice)
# ============================================================================

# Option 1: Azure OpenAI (Recommended for production)
# All Azure endpoints must be configured for full functionality
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# RAG Embeddings (for semantic search)
# Options (all 1536 dims):
#   - text-embedding-3-small (recommended, best quality)
#   - text-embedding-ada-002 (fallback if 3-small unavailable in your region)
# Create: az cognitiveservices account deployment create \
#   --name your-resource --resource-group your-rg \
#   --deployment-name text-embedding-ada-002 --model-name text-embedding-ada-002 \
#   --model-version 2 --model-format OpenAI --sku-capacity 10 --sku-name Standard
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002

# Voice Features (Azure OpenAI Realtime - REQUIRED for voice)
# Voice will not work without these - text chat fallback will be shown
#
# Available models (Dec 2025):
#   - gpt-realtime (2025-08-28) - GA, recommended, best quality
#   - gpt-realtime-mini (2025-12-15) - GA, faster, lower cost
#   - gpt-4o-realtime-preview (deprecated) - do NOT use
#
# Create deployment: az cognitiveservices account deployment create \
#   --name your-resource --resource-group your-rg \
#   --deployment-name gpt-realtime --model-name gpt-realtime --model-version 2025-08-28 \
#   --sku-name GlobalStandard --sku-capacity 1
#
AZURE_OPENAI_REALTIME_ENDPOINT=https://your-resource.openai.azure.com
AZURE_OPENAI_REALTIME_API_KEY=your-api-key
AZURE_OPENAI_REALTIME_DEPLOYMENT=gpt-realtime

# Cost Optimization: Use mini model by default, premium for MirrorBuddy only
# Mini model deployment (80-90% cheaper, good quality for most use cases)
# Premium model (AZURE_OPENAI_REALTIME_DEPLOYMENT) will be used ONLY for MirrorBuddy
AZURE_OPENAI_REALTIME_DEPLOYMENT_MINI=gpt-4o-mini-realtime

# Chat Streaming (ADR 0034)
# Enable real-time streaming for chat responses
# Set to 'false' to disable and use traditional request/response
ENABLE_CHAT_STREAMING=true

# Option 2: Ollama (100% local, free, chat/text only)
# If Azure is not configured, the app will automatically try Ollama
# Voice features will NOT work with Ollama (realtime audio not supported)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ============================================================================
# AZURE APPLICATION INSIGHTS (Optional - for OpenTelemetry observability)
# ============================================================================

# Azure Application Insights connection string for OpenTelemetry traces/spans
# If not set, telemetry will be disabled (development default)
#
# Get from Azure Portal:
# 1. Go to your Application Insights resource
# 2. Navigate to "Overview" or "Properties"
# 3. Copy the "Connection String"
#
# Format: InstrumentationKey=xxx;IngestionEndpoint=https://xxx.in.applicationinsights.azure.com/;LiveEndpoint=https://xxx.livediagnostics.monitor.azure.com/
APPLICATIONINSIGHTS_CONNECTION_STRING=your-app-insights-connection-string

# ============================================================================
# AZURE COST MANAGEMENT (Optional - for cost tracking in Settings)
# ============================================================================

# To enable cost tracking, you need a Service Principal with "Cost Management Reader" role:
#
# 1. Create App Registration in Azure AD:
#    az ad app create --display-name "mirrorbuddy Cost Reader"
#
# 2. Create Service Principal:
#    az ad sp create --id <app-id>
#
# 3. Create client secret:
#    az ad app credential reset --id <app-id>
#
# 4. Assign "Cost Management Reader" role on subscription:
#    az role assignment create \
#      --assignee <service-principal-id> \
#      --role "Cost Management Reader" \
#      --scope /subscriptions/<subscription-id>

AZURE_TENANT_ID=your-tenant-id
AZURE_CLIENT_ID=your-service-principal-client-id
AZURE_CLIENT_SECRET=your-service-principal-secret
AZURE_SUBSCRIPTION_ID=your-subscription-id

# ============================================================================
# GRAFANA CLOUD (Optional - for enterprise observability)
# ============================================================================

# Grafana Cloud remote write for Prometheus metrics
# Get from Grafana Cloud > Connections > Hosted Prometheus > Details
#
# URL format: https://prometheus-prod-XX-prod-{region}.grafana.net/api/prom/push
# User: numeric instance ID (e.g., 123456)
# API Key: create at Grafana Cloud > Access Policies > Create token with metrics:write
#
# If not configured, metrics are only available via pull at /api/metrics
GRAFANA_CLOUD_PROMETHEUS_URL=https://prometheus-prod-XX-prod-region.grafana.net/api/v1/push/influx/write
GRAFANA_CLOUD_PROMETHEUS_USER=your-instance-id
GRAFANA_CLOUD_API_KEY=your-grafana-cloud-api-key

# Push interval in seconds (default: 60, minimum: 15)
GRAFANA_CLOUD_PUSH_INTERVAL=60

# ============================================================================
# DATABASE (PostgreSQL with pgvector required)
# ============================================================================

# Option 1: Local development (requires PostgreSQL with pgvector extension)
# Install: brew install postgresql@17 && brew services start postgresql@17
# Setup:  createdb mirrorbuddy && psql -d mirrorbuddy -c "CREATE EXTENSION vector;"
# DATABASE_URL="postgresql://your-user@localhost:5432/mirrorbuddy"

# Option 2: Supabase via Vercel Marketplace (Recommended for production)
# Add Supabase from Vercel Dashboard > Storage > Create Database > Supabase
# These values are auto-populated by Vercel when you add Supabase
DATABASE_URL="postgres://postgres.YOUR_PROJECT_REF:YOUR_PASSWORD@aws-1-eu-west-1.pooler.supabase.com:6543/postgres?sslmode=require&pgbouncer=true"
DIRECT_URL="postgres://postgres.YOUR_PROJECT_REF:YOUR_PASSWORD@aws-1-eu-west-1.pooler.supabase.com:5432/postgres?sslmode=require"

# E2E Tests (dedicated test database)
TEST_DATABASE_URL="postgresql://your-user@localhost:5432/mirrorbuddy_test"
TEST_DIRECT_URL="postgresql://your-user@localhost:5432/mirrorbuddy_test"

# Supabase Client (for Supabase JS SDK if used)
NEXT_PUBLIC_SUPABASE_URL=https://xxxxx.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# ============================================================================
# RATE LIMITING (Upstash Redis)
# ============================================================================

# Add Upstash from Vercel Dashboard > Storage > Create Database > Upstash for Redis
# These values are auto-populated by Vercel when you add Upstash
UPSTASH_REDIS_REST_URL=https://xxxxx.upstash.io
UPSTASH_REDIS_REST_TOKEN=your-upstash-token

# ============================================================================
# TRANSACTIONAL EMAIL (Resend)
# ============================================================================

# Create account at resend.com and generate API key
# Used for: invite emails, credential notifications, password resets
RESEND_API_KEY=re_xxxxx

# ============================================================================
# WEB SEARCH (Brave Search API - for real-time information)
# ============================================================================

# Brave Search API enables maestri to access real-time web information
# (tech news, current events, sports results, etc.)
# Without this key, search falls back to Wikipedia only.
#
# Get your API key at: https://brave.com/search/api/
# Free tier: 2,000 queries/month
BRAVE_SEARCH_API_KEY=your-brave-search-api-key

# ============================================================================
# GOOGLE OAUTH (For Google Drive integration - ADR 0040)
# ============================================================================

# Google Drive integration allows users to import study materials directly
# from their Google Drive. Uses read-only scope (drive.readonly).
#
# Setup in Google Cloud Console:
# 1. Create/use existing project: console.cloud.google.com
# 2. Enable Google Drive API: APIs & Services > Library > Google Drive API
# 3. Create OAuth client: APIs & Services > Credentials > Create > OAuth client ID
# 4. Type: "Web application"
# 5. Authorized redirect URIs:
#    - Development: http://localhost:3000/api/auth/google/callback
#    - Production: https://your-domain.com/api/auth/google/callback
# 6. Copy Client ID and Client Secret below

GOOGLE_CLIENT_ID=your-web-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=your-web-client-secret

# Public client ID for Google Picker API (same as GOOGLE_CLIENT_ID, but exposed to browser)
NEXT_PUBLIC_GOOGLE_CLIENT_ID=your-web-client-id.apps.googleusercontent.com

# Required for OAuth callback URL generation
NEXTAUTH_URL=http://localhost:3000

# ============================================================================
# SESSION SECURITY
# ============================================================================

# Secret key for cryptographically signing session cookies (REQUIRED)
# Must be a strong random string (32+ characters recommended)
#
# Generate a secure secret:
#   node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
#   # OR
#   openssl rand -hex 32
#
# IMPORTANT: Keep this secret! Never commit to version control
# Use different secrets for dev/staging/production environments
SESSION_SECRET=your-random-64-character-hex-string-generated-above

# ============================================================================
# CRON JOB SECURITY (For scheduled tasks)
# ============================================================================

# Secret for protecting cron endpoints from unauthorized access
# Required by data retention cron job (/api/cron/data-retention)
# Vercel will include this in the Authorization header when invoking cron
#
# Generate a secure secret:
#   node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
#
# IMPORTANT: Must match in vercel.json cron configuration
CRON_SECRET=your-random-32-character-hex-string-for-cron

# ============================================================================
# PROVIDERS THAT ARE NEVER USED (listed for clarity)
# ============================================================================

# OPENAI_API_KEY=xxx        # DO NOT USE - Use Azure OpenAI instead
# ANTHROPIC_API_KEY=xxx     # DO NOT USE - Never use Anthropic

# ============================================================================
# ADMIN SEED (Plan 052 - MVP Beta)
# ============================================================================

# Admin user created on first deploy
# Used for /admin/* routes and initial system access
ADMIN_EMAIL=admin@yourdomain.com
ADMIN_PASSWORD=your-secure-admin-password

# ============================================================================
# TRIAL MODE (Plan 052 - MVP Beta)
# ============================================================================

# Monthly budget cap for trial users (in EUR)
# When exhausted, trial is suspended globally
TRIAL_BUDGET_LIMIT_EUR=100

# ============================================================================
# DOCKER DEPLOYMENT (docker-compose)
# ============================================================================

# PostgreSQL credentials for Docker containers
# REQUIRED when using docker-compose up
POSTGRES_USER=mirrorbuddy
POSTGRES_PASSWORD=your-secure-password-here
POSTGRES_DB=mirrorbuddy

# ============================================================================
# DEPLOYMENT NOTES
# ============================================================================
#
# 1. For Vercel deployment:
#    - Add these variables in Project Settings > Environment Variables
#
# 2. For local development:
#    - Copy this file: cp .env.example .env
#    - Fill in your credentials
#    - Setup PostgreSQL: createdb mirrorbuddy
#    - Run migrations: npx prisma migrate deploy
#    - Run: npm run dev
#
# ============================================================================
# OLLAMA QUICK START (100% local, no cloud, chat only)
# ============================================================================
#
#   # Install Ollama
#   brew install ollama
#
#   # Start server (keep running in terminal)
#   ollama serve
#
#   # Pull a model (in another terminal)
#   ollama pull llama3.2        # Fast, good for education (~2GB)
#   # OR
#   ollama pull mistral         # Alternative (~4GB)
#   # OR
#   ollama pull llama3.1:70b    # Best quality (needs 64GB+ RAM)
#
#   # Then just run the webapp - it will auto-detect Ollama
#   # Note: Voice features require Azure OpenAI Realtime
#
# ============================================================================
