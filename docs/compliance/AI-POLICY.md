# Politica di Trasparenza sull'Intelligenza Artificiale

## 1. Introduzione e Scopo

MirrorBuddy utilizza sistemi di intelligenza artificiale (IA) per supportare studenti con difficoltà di apprendimento. Questa politica illustra come implementiamo, gestiamo e supervisioniamo tali sistemi in conformità alle normative europee e italiane, garantendo trasparenza, sicurezza e protezione dei diritti degli utenti.

## 2. Quadro Normativo

Questa politica è redatta in conformità a:

- **AI Act** (Regolamento UE 2024/1689): Disciplina i sistemi di IA basati sul rischio, con maggior attenzione ai sistemi ad alto rischio in ambito educativo e protezione dei minori
- **Legge 132/2025** (Disposizioni per l'implementazione dell'AI Act): Recepisce la normativa europea nell'ordinamento italiano, stabilendo responsabilità dei fornitori e diritti degli utenti
- **GDPR** (Regolamento UE 2016/679): Protezione dei dati personali e diritti alla privacy
- **Codice della Privacy italiano** (D.Lgs. 196/2003): Implementazione nazionale della protezione dati

## 3. Principi Guida

MirrorBuddy aderisce ai seguenti principi nel deployment di sistemi IA:

- **Trasparenza**: Gli utenti sono sempre informati quando interagiscono con IA
- **Supervisione Umana**: Gli insegnanti mantengono pieno controllo pedagogico e decisionale
- **Non-Discriminazione**: I sistemi sono testati per bias e disparità nei risultati
- **Sicurezza**: Misure tecniche e procedurali proteggono da usi dannosi
- **Autonomia**: Nessuna decisione con effetti legali è presa da sistemi automatizzati

## 4. Classificazione del Sistema

MirrorBuddy è classificato come **sistema IA ad alto rischio** (Art. 6, AI Act) perché:

- **Ambito educativo**: Supporta l'apprendimento di minori
- **Protezione dei minori**: Elabora dati sensibili di studenti con diagnosi di disabilità cognitiva
- **Impatto significativo**: Influenza percorsi didattici e sviluppo cognitivo
- **Dati biometrici**: Gestisce dati biometrici (voce) per l'accesso e il riconoscimento

Conseguentemente, implementiamo misure di trasparenza, conformità e supervisione secondo il Capo III dell'AI Act.

## 5. Misure di Trasparenza

Tutti gli utenti sono informati che:

- Le risposte didattiche sono generate da **Azure OpenAI (GPT-4)**, provider IA certificato
- I 22 "Maestri IA" (tutori virtuali) hanno **embedded knowledge bases** verificate, non generano contenuto liberamente
- Un **banner di trasparenza** informa gli studenti di stare interagendo con IA ogni volta che accedono a funzioni AI-driven
- Le chat educative sono sempre **human-reviewable** da insegnanti e genitori
- Il **sistema di generazione voce** utilizza modelli OpenAI con monitoraggio della qualità

## 6. Supervisione Umana

MirrorBuddy implementa supervisione umana continua:

- **Insegnanti**: Accesso completo a transcript di chat e metriche di engagement; possibilità di intervenire o terminare sessioni IA
- **Genitori**: Visione delle attività IA dei figli e diritto di revoca del consenso in qualsiasi momento
- **Amministratori**: Monitoraggio dei pattern di utilizzo IA per identificare anomalie o rischi
- **Review periodici**: Audit tecnico trimestrale dei sistemi IA e output generati

## 7. Protezione dei Minori

Misure speciali proteggono gli studenti minori:

- **Doppio Consenso** (AI Act, Art. 7): Consenso richiesto sia a genitori che a studenti per utilizzo di sistemi IA
- **Content Filtering**: Sistemi IA non generano contenuti violenti, espliciti o inadatti all'età
- **Limiti di Utilizzo**: Studenti hanno budget giornaliero di interazioni IA per prevenire dipendenza
- **Accessibilità**: I sistemi IA rispettano WCAG 2.1 AA e le 7 esigenze di accessibilità (dislessia, ADHD, etc.)
- **Monitoraggio Psico-Comportamentale**: Sistemi detection per segnalare pattern di distress negli studenti

## 8. Gestione dei Rischi

Identifichiamo e mitigiamo rischi specifici:

| Rischio                                       | Probabilità | Mitigazione                                  |
| --------------------------------------------- | ----------- | -------------------------------------------- |
| Generazione di contenuti inappropriati        | Bassa       | Content filtering + human review             |
| Dipendenza da IA                              | Media       | Budget limits + parental controls            |
| Bias nei confronti di studenti con disabilità | Bassa       | Bias testing bimestrale + diverse datasets   |
| Privacy breach di dati sensibili              | Bassa       | Encryption at-rest/transit + GDPR compliance |
| Malfunzionamento IA durante assessment        | Media       | Fallback a provider Ollama + manual mode     |

## 9. Diritti degli Utenti

Gli utenti hanno diritto a:

- **Informazione**: Sapere quando un'IA decide o fornisce una risposta (Art. 13, L.132/2025)
- **Spiegazione**: Capire il ragionamento dietro risposte didattiche
- **Revoca del Consenso**: Rifiutare in qualunque momento l'utilizzo di IA, senza penalità
- **Accesso ai Dati**: Richiedere copia di tutte le interazioni IA e feedback generati (GDPR Art. 15)
- **Rettifica**: Correggere dati inesatti processati da sistemi IA
- **Cancellazione**: Richiedere eliminazione di dati in conformità GDPR

## 10. Contatti e Reclami

Per segnalare preoccupazioni sull'uso di IA in MirrorBuddy:

- **Email**: compliance@mirrorbuddy.it
- **Modulo Online**: www.mirrorbuddy.it/privacy/ai-complaint
- **Supervisore**: Autorità Garante per la Protezione dei Dati Personali (www.garanteprivacy.it)
- **Ricorso**: Diritto a ricorso presso autorità nazionale di vigilanza sull'AI (AGID)

Rispondiamo a reclami entro 30 giorni lavorativi.

## 11. Revisione e Aggiornamento

Questa politica è sottoposta a:

- **Revisione Annuale**: Aggiornamento alla luce di nuove normative (AI Act, L.132/2025)
- **Update Tecnico**: Notifica entro 14 giorni da cambiamenti nei sistemi IA utilizzati
- **Stakeholder Feedback**: Consultazione annuale con insegnanti, genitori, regolatori
- **Comunicazione**: Modifiche significative comunicate via email a tutti gli utenti attivi

**Data ultimo aggiornamento**: 20 Gennaio 2026
**Data prossima revisione**: 20 Gennaio 2027

---

_MirrorBuddy è impegnata a operare secondo i più alti standard di trasparenza e responsabilità nell'utilizzo dell'intelligenza artificiale a beneficio dell'educazione inclusiva._
