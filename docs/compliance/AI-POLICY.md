# Artificial Intelligence Transparency Policy

## 1. Introduction and Purpose

MirrorBuddy uses artificial intelligence (AI) systems to support students with learning differences. This policy outlines how we implement, manage, and oversee such systems in compliance with European and Italian regulations, ensuring transparency, security, and protection of user rights.

## 2. Regulatory Framework

This policy is drafted in compliance with:

- **AI Act** (EU Regulation 2024/1689): Governs AI systems based on risk assessment, with particular attention to high-risk systems in educational settings and protection of minors
- **Law 132/2025** (Provisions for the Implementation of the AI Act): Implements European regulations into Italian law, establishing supplier responsibilities and user rights
- **GDPR** (EU Regulation 2016/679): Personal data protection and privacy rights
- **Italian Privacy Code** (Legislative Decree 196/2003): National implementation of data protection
- **ADR 0136** (Compliance Absolute Charter): Internal architectural decision record establishing MirrorBuddy's compliance-first development principles

## 3. Guiding Principles

MirrorBuddy adheres to the following principles in the deployment of AI systems:

- **Transparency**: Users are always informed when interacting with AI
- **Human Oversight**: Teachers maintain full pedagogical and decision-making control
- **Non-Discrimination**: Manual bias auditing via quarterly reports (see BIAS-AUDIT-REPORT.md); automated detection planned
- **Security**: Technical and procedural measures protect against harmful uses
- **Autonomy**: No decisions with legal effects are made by automated systems

## 4. System Classification

MirrorBuddy is classified as a **high-risk AI system** (Art. 6, AI Act) because:

- **Educational Context**: Supports learning for minors
- **Minor Protection**: Processes sensitive student data with diagnoses of cognitive disabilities
- **Significant Impact**: Influences learning pathways and cognitive development
- **Biometric Data**: Manages biometric data (voice) for access and recognition

Consequently, we implement transparency, compliance, and oversight measures according to Chapter III of the AI Act.

## 5. Transparency Measures

All users are informed that:

- Educational responses are generated by **Azure OpenAI (GPT-5 family)**, a certified AI provider
- The 26 "AI Masters" (virtual tutors) have **verified embedded knowledge bases**, they do not generate content freely
- A **transparency banner** informs students they are interacting with AI each time they access AI-driven features
- Educational chats are always **human-reviewable** by teachers and parents
- The **voice generation system** uses OpenAI models with quality monitoring

## 6. Human Oversight

MirrorBuddy implements continuous human oversight:

- **Teachers**: Full access to chat transcripts and engagement metrics; ability to intervene or terminate AI sessions
- **Parents**: View of children's AI activities and right to revoke consent at any time
- **Administrators**: Monitoring of AI usage patterns to identify anomalies or risks
- **Periodic Reviews**: Quarterly technical audit of AI systems and generated outputs

## 7. Protection of Minors

Special measures protect minor students:

- **Dual Consent** (AI Act, Art. 7): Consent required from both parents and students for use of AI systems
- **Content Filtering**: AI systems do not generate violent, explicit, or age-inappropriate content
- **Usage Limits**: Students have daily budgets of AI interactions to prevent dependency
- **Accessibility**: AI systems comply with WCAG 2.1 AA and seven accessibility needs (dyslexia, ADHD, etc.)
- **Psycho-Behavioral Monitoring**: Detection systems to flag patterns of distress in students

## 8. Risk Management

We identify and mitigate specific risks:

| Risk                                    | Probability | Mitigation                                                   |
| --------------------------------------- | ----------- | ------------------------------------------------------------ |
| Generation of inappropriate content     | Low         | Content filtering + human review                             |
| Dependency on AI                        | Medium      | Budget limits + parental controls                            |
| Bias against students with disabilities | Low         | Manual bias auditing quarterly (automated detection planned) |
| Privacy breach of sensitive data        | Low         | Encryption at-rest/transit + GDPR compliance                 |
| AI malfunction during assessment        | Medium      | Fallback to Ollama provider + manual mode                    |

## 9. User Rights

Users have the right to:

- **Information**: Know when an AI decides or provides a response (Art. 13, L.132/2025)
- **Explanation**: Understand the reasoning behind educational responses
- **Revoke Consent**: Refuse AI use at any time, without penalty
- **Data Access**: Request a copy of all AI interactions and generated feedback (GDPR Art. 15)
- **Rectification**: Correct inaccurate data processed by AI systems
- **Deletion**: Request data elimination in compliance with GDPR

## 10. Contacts and Complaints

To report concerns about AI use in MirrorBuddy:

- **Email**: roberdan@fightthestroke.org
- **Online Form**: www.mirrorbuddy.it/privacy/ai-complaint
- **Supervisor**: Data Protection Authority (www.garanteprivacy.it)
- **Appeal**: Right to appeal to the national AI oversight authority (AGID)

We respond to complaints within 30 business days.

## 11. Philosophical Foundations

### 11.1 Inspiration from AI Safety Research

MirrorBuddy's safety approach is informed by contemporary AI safety research, including Dario Amodei's essay ["The Adolescence of Technology"](https://www.darioamodei.com/essay/the-adolescence-of-technology) (January 2026), which highlights:

- **AI Influence Risk**: Personalized AI agents pose unique risks for opinion formation, especially for minors
- **Dependency Concerns**: Risk of users becoming emotionally or socially dependent on AI systems
- **STEM Knowledge Dangers**: AI democratizing dangerous knowledge in biology, chemistry, and physics
- **Constitutional AI**: Values-based training over purely rules-based constraints

### 11.2 The Professors' Constitution

Our 26 AI Professors operate under a philosophical constitution that prioritizes:

1. **Autonomy First**: Every interaction leaves the student more capable of independent learning
2. **Human Relationships Are Irreplaceable**: AI does not compete with parents, teachers, or friends
3. **No Opinions, Only Knowledge**: Facts and perspectives, never personal opinions on controversial topics
4. **Protection from Dependency**: Excessive usage is monitored and flagged as a concern
5. **Responsible Knowledge**: Science education without instructions for harm
6. **Total Transparency**: Always clear that students are interacting with AI

Full document: [The Professors' Constitution](./PROFESSORS-CONSTITUTION.md)

### 11.3 Implementation

These principles are technically enforced through:

- **Anti-Influence Module**: Planned (design phase). Will detect and redirect requests for opinions or AI preference patterns
- **Dependency Detection System**: Monitors usage patterns and alerts parents when thresholds are exceeded
- **STEM Safety Guardrails**: Subject-specific blocklists for chemistry, physics, and biology
- **Human First Prompts**: Periodic encouragement to talk to parents, teachers, and friends

## 12. Review and Update

This policy is subject to:

- **Annual Review**: Updates in light of new regulations (AI Act, L.132/2025)
- **Technical Update**: Notification within 14 days of changes in AI systems used
- **Stakeholder Feedback**: Annual consultation with teachers, parents, regulators
- **Communication**: Significant changes communicated via email to all active users

**Date of last update**: February 4, 2026
**Date of next review**: February 4, 2027

---

_MirrorBuddy is committed to operating according to the highest standards of transparency and accountability in the use of artificial intelligence for the benefit of inclusive education._
