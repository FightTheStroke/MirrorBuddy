# Artificial Intelligence Transparency Policy

## 1. Introduction and Purpose

MirrorBuddy uses artificial intelligence (AI) systems to support students with learning differences. This policy outlines how we implement, manage, and oversee such systems in compliance with European and Italian regulations, ensuring transparency, security, and protection of user rights.

## 2. Regulatory Framework

This policy is drafted in compliance with:

- **AI Act** (EU Regulation 2024/1689): Governs AI systems based on risk assessment, with particular attention to high-risk systems in educational settings and protection of minors
- **Law 132/2025** (Provisions for the Implementation of the AI Act): Implements European regulations into Italian law, establishing supplier responsibilities and user rights
- **GDPR** (EU Regulation 2016/679): Personal data protection and privacy rights
- **Italian Privacy Code** (Legislative Decree 196/2003): National implementation of data protection

## 3. Guiding Principles

MirrorBuddy adheres to the following principles in the deployment of AI systems:

- **Transparency**: Users are always informed when interacting with AI
- **Human Oversight**: Teachers maintain full pedagogical and decision-making control
- **Non-Discrimination**: Systems are tested for bias and disparities in outcomes
- **Security**: Technical and procedural measures protect against harmful uses
- **Autonomy**: No decisions with legal effects are made by automated systems

## 4. System Classification

MirrorBuddy is classified as a **high-risk AI system** (Art. 6, AI Act) because:

- **Educational Context**: Supports learning for minors
- **Minor Protection**: Processes sensitive student data with diagnoses of cognitive disabilities
- **Significant Impact**: Influences learning pathways and cognitive development
- **Biometric Data**: Manages biometric data (voice) for access and recognition

Consequently, we implement transparency, compliance, and oversight measures according to Chapter III of the AI Act.

## 5. Transparency Measures

All users are informed that:

- Educational responses are generated by **Azure OpenAI (GPT-4)**, a certified AI provider
- The 22 "AI Masters" (virtual tutors) have **verified embedded knowledge bases**, they do not generate content freely
- A **transparency banner** informs students they are interacting with AI each time they access AI-driven features
- Educational chats are always **human-reviewable** by teachers and parents
- The **voice generation system** uses OpenAI models with quality monitoring

## 6. Human Oversight

MirrorBuddy implements continuous human oversight:

- **Teachers**: Full access to chat transcripts and engagement metrics; ability to intervene or terminate AI sessions
- **Parents**: View of children's AI activities and right to revoke consent at any time
- **Administrators**: Monitoring of AI usage patterns to identify anomalies or risks
- **Periodic Reviews**: Quarterly technical audit of AI systems and generated outputs

## 7. Protection of Minors

Special measures protect minor students:

- **Dual Consent** (AI Act, Art. 7): Consent required from both parents and students for use of AI systems
- **Content Filtering**: AI systems do not generate violent, explicit, or age-inappropriate content
- **Usage Limits**: Students have daily budgets of AI interactions to prevent dependency
- **Accessibility**: AI systems comply with WCAG 2.1 AA and seven accessibility needs (dyslexia, ADHD, etc.)
- **Psycho-Behavioral Monitoring**: Detection systems to flag patterns of distress in students

## 8. Risk Management

We identify and mitigate specific risks:

| Risk                                    | Probability | Mitigation                                   |
| --------------------------------------- | ----------- | -------------------------------------------- |
| Generation of inappropriate content     | Low         | Content filtering + human review             |
| Dependency on AI                        | Medium      | Budget limits + parental controls            |
| Bias against students with disabilities | Low         | Bimonthly bias testing + diverse datasets    |
| Privacy breach of sensitive data        | Low         | Encryption at-rest/transit + GDPR compliance |
| AI malfunction during assessment        | Medium      | Fallback to Ollama provider + manual mode    |

## 9. User Rights

Users have the right to:

- **Information**: Know when an AI decides or provides a response (Art. 13, L.132/2025)
- **Explanation**: Understand the reasoning behind educational responses
- **Revoke Consent**: Refuse AI use at any time, without penalty
- **Data Access**: Request a copy of all AI interactions and generated feedback (GDPR Art. 15)
- **Rectification**: Correct inaccurate data processed by AI systems
- **Deletion**: Request data elimination in compliance with GDPR

## 10. Contacts and Complaints

To report concerns about AI use in MirrorBuddy:

- **Email**: info@fightthestroke.org
- **Online Form**: www.mirrorbuddy.it/privacy/ai-complaint
- **Supervisor**: Data Protection Authority (www.garanteprivacy.it)
- **Appeal**: Right to appeal to the national AI oversight authority (AGID)

We respond to complaints within 30 business days.

## 11. Review and Update

This policy is subject to:

- **Annual Review**: Updates in light of new regulations (AI Act, L.132/2025)
- **Technical Update**: Notification within 14 days of changes in AI systems used
- **Stakeholder Feedback**: Annual consultation with teachers, parents, regulators
- **Communication**: Significant changes communicated via email to all active users

**Date of last update**: January 20, 2026
**Date of next review**: January 20, 2027

---

_MirrorBuddy is committed to operating according to the highest standards of transparency and accountability in the use of artificial intelligence for the benefit of inclusive education._
